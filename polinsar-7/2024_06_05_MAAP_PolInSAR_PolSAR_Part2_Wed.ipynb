{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# The PolInSAR Course - June 3rd, 2024\n",
    "# SAR Polarimetry (PolSAR) \n",
    "# Part 2: Eigenvalues of the Polarimetric Coherency Matrix and the Entropy/Anisotropy/Alpha decomposition"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Acquisition: Nkok (Gabon), DLR's F-SAR, L-band\n",
    "\n",
    "* Path to images: /projects/data/polsar/\n",
    "\n",
    "* SLC (single-look complex) images:\n",
    "    * HH: slc_16afrisr0107_Lhh_tcal_test.rat\n",
    "    * HV: slc_16afrisr0107_Lhv_tcal_test.rat\n",
    "    * VH: slc_16afrisr0107_Lvh_tcal_test.rat\n",
    "    * VV: slc_16afrisr0107_Lvv_tcal_test.rat\n",
    "\n",
    "Tips:\n",
    "- use a function that performs the multilook (correlation) operation on a moving window with (looksa x looksr) pixels in range - azimuth\n",
    "- focus on a azimuth - range block within pixels [5000, 15000] and [0, 2000], respectively."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Download exercise data & import reader function\n",
    "from pysarpro import io, data\n",
    "from pysarpro.io import rrat\n",
    "\n",
    "data.download_all(directory=\"/projects\", pattern=r'^data/polsar')\n",
    "\n",
    "# --- Import useful libaries, functions, and modules\n",
    "import sys\n",
    "sys.path.append('/projects/src/')\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from scipy.ndimage import uniform_filter\n",
    "%matplotlib widget"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Auxiliary functions**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`HSV_colormap_to_rgb`: Generates and HSV composite representation based on a given colormap."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def HSV_colormap_to_rgb(colormap, h, s, v):\n",
    "    \"\"\"\n",
    "    Makes an HSV-like RGB representation based on the given colormap instead\n",
    "    of 'hsv' colormap.\n",
    "    \n",
    "    See https://en.wikipedia.org/wiki/HSL_and_HSV\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    colormap : function\n",
    "        Colormap function. Takes the values in 'h' array and returns an RGBA\n",
    "        value for each point. The ones in matplotlib.cm should be compatible\n",
    "    h : ndarray\n",
    "        Hue values. Usually between 0 and 1.0.\n",
    "    s : ndarray\n",
    "        Saturation values. Between 0 and 1.0.\n",
    "    v : ndarray\n",
    "        Value values. Between 0 and 1.0.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    rgb: ndarray\n",
    "        An array with the same shape as input + (3,) representing the RGB.\n",
    "    \"\"\"\n",
    "    # Generate color between given colormap (colormap(h)) and white (ones)\n",
    "    # according to the given saturation\n",
    "    tmp = (1-s)[..., np.newaxis]*np.ones(3) + s[..., np.newaxis] * colormap(h)[...,:3]\n",
    "    # Scale it by value\n",
    "    return v[..., np.newaxis] * tmp"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`calculate_covariance`: Calculates the covariance between two images while performing a multi-looking operation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_covariance(im1, im2, looksa, looksr):\n",
    "    \n",
    "     # ... apply definition\n",
    "    corr = uniform_filter( np.real(im1*np.conj(im2)), [looksa, looksr] ) + \\\n",
    "        1j*uniform_filter( np.imag(im1*np.conj(im2)), [looksa, looksr] )\n",
    "    \n",
    "    # ... and back to main\n",
    "    return corr"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`calculate_eigenvalues_3`: Computes the eigenvalues of a 3x3 matrix analytically. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_eigenvalues_3(T11, T12, T13, T22, T23, T33):\n",
    "\n",
    "    # Calculate and order (from max to min) the eigenvalues of a 3x3 hermitian matrix in closed-form.\n",
    "    # Inputs can be 2D az - rg (rows - columns).\n",
    "\n",
    "    # get dimensions\n",
    "    dims = T11.shape\n",
    "\n",
    "    # calculate auxiliary quantities\n",
    "    A = T11*T22 + T11*T33 + T22*T33 - T12*np.conj(T12) - T13*np.conj(T13) - T23*np.conj(T23)\n",
    "    B = T11**2 - T11*T22 + T22**2 -T11*T33 -T22*T33 + T33**2 + 3*T12*np.conj(T12) + 3*T13*np.conj(T13) + 3*T23*np.conj(T23)\n",
    "\n",
    "    DET = T11*T22*T33 - T33*T12*np.conj(T12) - T22*T13*np.conj(T13) - T11*T23*np.conj(T23) + T12*np.conj(T13)*T23 + np.conj(T12)*T13*np.conj(T23)  \n",
    "    TR = T11 + T22 + T33 \n",
    "    Z = 27*DET-9*A*TR + 2*TR**3 + np.sqrt((27*DET-9*A*TR + 2*TR**3)**2-4*B**3)\n",
    "    \n",
    "    del DET\n",
    "    \n",
    "    # ... and here they are:\n",
    "    LA = ( 1/3.*TR + 2**(1/3.)*B/(3*Z**(1/3.)) + Z**(1/3.)/(3*2**(1/3.)) )\n",
    "    LB = ( 1/3.*TR - (1+1j*np.sqrt(3))*B/(3*2**(2/3.)*Z**(1/3.)) - (1-1j*np.sqrt(3))*Z**(1/3.)/(6*2**(1/3.)) )\n",
    "    LC = ( 1/3.*TR - (1-1j*np.sqrt(3))*B/(3*2**(2/3.)*Z**(1/3.)) - (1+1j*np.sqrt(3))*Z**(1/3.)/(6*2**(1/3.)) )\n",
    "    \n",
    "    # now order them:\n",
    "    dumm = np.zeros((dims[0], dims[1], 3), 'float32')\n",
    "    dumm [:, :, 0] = np.real(LA)\n",
    "    dumm [:, :, 1] = np.real(LB)\n",
    "    dumm [:, :, 2] = np.real(LC)\n",
    "    \n",
    "    del LA, LB, LC  \n",
    "    \n",
    "    L1 = np.max(dumm, axis = 2)\n",
    "    L3 = np.min(dumm, axis = 2)\n",
    "    L2 = np.sum(dumm, axis = 2) - L1 - L3\n",
    "    \n",
    "    del dumm\n",
    "    \n",
    "    return L1, L2, L3\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`calculate_eigenvectors_3`: Computes the eigenvectors of a 3x3 matrix analytically. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_eigenvectors_3(T11, T12, T13, T22, T23, T33, L1, L2, L3) :\n",
    "\n",
    "    # Calculate the eigenvectors corresponding to the eigenvalues (L1, L2, L3)\n",
    "    # of a 3x3 matrix \n",
    "    # Inputs can be 2D az - rg (rows - columns).\n",
    "\n",
    "    # get dimensions\n",
    "    dims = T11.shape    \n",
    "    \n",
    "    # first eigenvector - corresponds to the maximum eigenvalue L1\n",
    "    U1 = np.ones((dims[0], dims[1], 3), 'complex64')\n",
    "    U1[:, :, 0] = (L1 -T33)/np.conj(T13) + (((L1-T33)*np.conj(T12) + np.conj(T13)*T23)*np.conj(T23))/ \\\n",
    "                    (((T22-L1)*np.conj(T13) - np.conj(T12)*np.conj(T23))*np.conj(T13))\n",
    "    U1[:, :, 1] = -((L1-T33)*np.conj(T12)+np.conj(T13)*T23) / ((T22-L1)*np.conj(T13) - np.conj(T12)*np.conj(T23))\n",
    "    \n",
    "    # second eigenvector - corresponds to the eigenvalue L2\n",
    "    U2 = np.ones((dims[0], dims[1], 3), 'complex64')\n",
    "    U2[:, :, 0] = (L2 -T33)/np.conj(T13) + (((L2-T33)*np.conj(T12) + np.conj(T13)*T23)*np.conj(T23))/ \\\n",
    "                    (((T22-L2)*np.conj(T13) - np.conj(T12)*np.conj(T23))*np.conj(T13))\n",
    "    U2[:, :, 1] = -((L2-T33)*np.conj(T12)+np.conj(T13)*T23) / ((T22-L2)*np.conj(T13) - np.conj(T12)*np.conj(T23))\n",
    "    \n",
    "    # third eigenvector - corresponds to the minimum eigenvalue L3\n",
    "    U3 = np.ones((dims[0], dims[1], 3), 'complex64')\n",
    "    U3[:, :, 0] = (L3 -T33)/np.conj(T13) + (((L3-T33)*np.conj(T12) + np.conj(T13)*T23)*np.conj(T23))/ \\\n",
    "                    (((T22-L3)*np.conj(T13) - np.conj(T12)*np.conj(T23))*np.conj(T13))\n",
    "    U3[:, :, 1] = -((L3-T33)*np.conj(T12)+np.conj(T13)*T23) / ((T22-L3)*np.conj(T13) - np.conj(T12)*np.conj(T23))   \n",
    "    \n",
    "    # normalize to get orthonormal eigenvectors\n",
    "    norm1 = np.sqrt( np.abs(U1[:,:,0])**2 + np.abs(U1[:,:,1])**2 + np.abs(U1[:,:,2])**2)\n",
    "    norm2 = np.sqrt( np.abs(U2[:,:,0])**2 + np.abs(U2[:,:,1])**2 + np.abs(U2[:,:,2])**2)    \n",
    "    norm3 = np.sqrt( np.abs(U3[:,:,0])**2 + np.abs(U3[:,:,1])**2 + np.abs(U3[:,:,2])**2)        \n",
    "    for nn in range(3):\n",
    "        U1[:,:,nn] = U1[:,:,nn] / norm1\n",
    "        U2[:,:,nn] = U2[:,:,nn] / norm2\n",
    "        U3[:,:,nn] = U3[:,:,nn] / norm3\n",
    "        \n",
    "    del norm1, norm2, norm3     \n",
    "    \n",
    "    return U1, U2, U3\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Input parameters**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# path to the data\n",
    "path = '/projects/data/polsar/'\n",
    "# define the number of looks \n",
    "looksa = 7\n",
    "looksr = 7"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Step 1: Load data**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "slcHH = rrat(path + 'slc_16afrisr0107_Lhh_tcal_test.rat', block=[5000,15000,0,2000])\n",
    "slcHV = rrat(path + 'slc_16afrisr0107_Lhv_tcal_test.rat', block=[5000,15000,0,2000])\n",
    "slcVV = rrat(path + 'slc_16afrisr0107_Lvv_tcal_test.rat', block=[5000,15000,0,2000])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check shape\n",
    "slcHH.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Step 2: Calculate the necessary elements of the coherency matrix**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# -- compute the Pauli components\n",
    "pauli1 = slcHH + slcVV\n",
    "pauli2 = slcHH - slcVV\n",
    "pauli3 = 2*slcHV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# -- compute the elements of the coherency matrix\n",
    "T11 = calculate_covariance(pauli1, pauli1, looksa, looksr)\n",
    "T22 = calculate_covariance(pauli2, pauli2, looksa, looksr)\n",
    "T33 = calculate_covariance(pauli3, pauli3, looksa, looksr)\n",
    "T12 = calculate_covariance(pauli1, pauli2, looksa, looksr)\n",
    "T13 = calculate_covariance(pauli1, pauli3, looksa, looksr)\n",
    "T23 = calculate_covariance(pauli2, pauli3, looksa, looksr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# -- delete unused variables\n",
    "del slcHH, slcHV, slcVV\n",
    "del pauli1, pauli2, pauli3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Step 3: Calculate eigenvalues**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lambda1, lambda2, lambda3 = calculate_eigenvalues_3(T11, T12, T13, T22, T23, T33)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check shape\n",
    "lambda1.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Step 4: Calculate entropy**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# -- compute the probabilities associated with each eigenvalue\n",
    "pr1 = lambda1 / (lambda1 + lambda2 + lambda3)\n",
    "pr2 = lambda2 / (lambda1 + lambda2 + lambda3)\n",
    "pr3 = lambda3 / (lambda1 + lambda2 + lambda3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# -- compute the entropy\n",
    "entropy = -(pr1 * np.log10(pr1)/np.log10(3) + pr2 * np.log10(pr2)/np.log10(3) + pr3 * np.log10(pr3)/np.log10(3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Step 5: Calculate anisotropy** "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# -- compute the anisotropy (related to the minimum and intermediate eigenvalues)\n",
    "# A = 0 when lambda2 = lambda3\n",
    "# A = 1 when lambda2 >> lambda3 \n",
    "anisotropy =  (lambda2 - lambda3) / (lambda2 + lambda3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Step 6: Calculate eigenvectors**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# -- compute the eigenvectors\n",
    "U1, U2, U3 = calculate_eigenvectors_3(T11, T12, T13, T22, T23, T33, lambda1, lambda2, lambda3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check shape\n",
    "U1.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# -- delete unused variables\n",
    "del T12, T13, T23"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Step 7: Calculate mean alpha angle**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# -- extract the alpha angles\n",
    "alpha1 = np.arccos(np.abs(U1[:,:,0]))  # [rad]\n",
    "alpha2 = np.arccos(np.abs(U2[:,:,0]))\n",
    "alpha3 = np.arccos(np.abs(U3[:,:,0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# -- delete unused variables\n",
    "del U1, U2, U3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# -- compute the mean alpha angle\n",
    "alpha_mean = pr1*alpha1 + pr2*alpha2 + pr3*alpha3\n",
    "# -- transfer to degrees\n",
    "alpha_mean = np.degrees(alpha_mean)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Step 8: Plots!**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculations for Paulis RGB:\n",
    "# -- define the 3D array for the Pauli representation\n",
    "dimaz = T11.shape[0]\n",
    "dimrg = T11.shape[1]\n",
    "rgb_pauli = np.zeros((dimrg, dimaz,3), 'float32')\n",
    "\n",
    "# -- fill the array, clipping the values between 0 and 2.5xmean(amplitude)\n",
    "rgb_pauli[:,:,0] =np.clip(np.transpose(np.sqrt(abs(T22))), 0, 2.5*np.mean(np.sqrt(abs(T22)))) # R: HH-VV\n",
    "rgb_pauli[:,:,1] =np.clip(np.transpose(np.sqrt(abs(T33))), 0, 2.5*np.mean(np.sqrt(abs(T33)))) # G: HV\n",
    "rgb_pauli[:,:,2] =np.clip(np.transpose(np.sqrt(abs(T11))), 0, 2.5*np.mean(np.sqrt(abs(T11)))) # B: HH+VV\n",
    "\n",
    "# -- normalisation: values between 0 and 1\n",
    "rgb_pauli[:,:,0] = rgb_pauli[:,:,0] / np.max(rgb_pauli[:,:,0])\n",
    "rgb_pauli[:,:,1] = rgb_pauli[:,:,1] / np.max(rgb_pauli[:,:,1])\n",
    "rgb_pauli[:,:,2] = rgb_pauli[:,:,2] / np.max(rgb_pauli[:,:,2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot: Pauli RGB and eigenvalue probabilities\n",
    "plt.figure(figsize=(15, 6*4))\n",
    "plt.subplot(4,1,1)\n",
    "plt.imshow(rgb_pauli, aspect='auto')\n",
    "plt.colorbar()\n",
    "\n",
    "plt.subplot(4,1,2)\n",
    "plt.imshow(np.transpose(pr1), cmap='turbo', vmin=0, vmax=1, aspect='auto')\n",
    "cb = plt.colorbar()\n",
    "cb.set_label('pr1')\n",
    "\n",
    "plt.subplot(4,1,3)\n",
    "plt.imshow(np.transpose(pr2), cmap='turbo', vmin=0, vmax=1, aspect='auto')\n",
    "cb = plt.colorbar()\n",
    "cb.set_label('pr2')\n",
    "\n",
    "plt.subplot(4,1,4)\n",
    "plt.imshow(np.transpose(pr3), cmap='turbo', vmin=0, vmax=1, aspect='auto')\n",
    "cb = plt.colorbar()\n",
    "cb.set_label('pr3')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot: H, A, alpha\n",
    "plt.figure(figsize=(15, 6*3))\n",
    "\n",
    "plt.subplot(3,1,1)\n",
    "plt.imshow(np.transpose(entropy), cmap='gray', vmin=0, vmax=1, aspect='auto')\n",
    "cb = plt.colorbar()\n",
    "cb.set_label('Entropy H')\n",
    "\n",
    "plt.subplot(3,1,2)\n",
    "plt.imshow(np.transpose(anisotropy), cmap='turbo', vmin=0, vmax=1, aspect='auto')\n",
    "cb = plt.colorbar()\n",
    "cb.set_label('Anisotropy A')\n",
    "\n",
    "plt.subplot(3,1,3)\n",
    "plt.imshow(np.transpose(alpha_mean), cmap='turbo', vmin=0, vmax=90, aspect='auto')\n",
    "cb = plt.colorbar()\n",
    "cb.set_label('Mean alpha angle [deg]')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# HSI Color Representation:\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    " HSI Color Representation:\n",
    "- H (hue):  mean alpha angle\n",
    "- S (saturation): \n",
    "     - Case 1: saturation = 1: always full colorscale\n",
    "     - Case 2:  saturation = 1 - entropy\n",
    "          - when entropy = 0: then saturation = 1: full colorscale\n",
    "          - when entropy = 1: then saturation = 0: grayscale\n",
    "- I (intensity): amplitude of total power"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hue: mean alpha angle\n",
    "# normalize the mean alpha angle: it has to be between 0 and 1 --> divide by 90 degrees\n",
    "hue = alpha_mean / 90 \n",
    "\n",
    "# Import the colormap for plotting alpha\n",
    "colormap = plt.colormaps.get('turbo')\n",
    "\n",
    "# Intensity: normalize the amplitude\n",
    "amp = np.sqrt(abs(T11) + abs(T22) + abs(T33))\n",
    "amp = np.clip(amp, 0, 2.5*np.mean(amp))\n",
    "amp = amp / np.max(amp)\n",
    "\n",
    "# Saturation\n",
    "# Case 1)\n",
    "sat1 = np.ones_like(amp)\n",
    "# Case 2)\n",
    "sat2 = 1 - entropy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate the HSV colormaps \n",
    "\n",
    "# Case 1\n",
    "rgb_comp1 = HSV_colormap_to_rgb(colormap, hue, sat1, amp)\n",
    "\n",
    "# Case 2\n",
    "rgb_comp2 = HSV_colormap_to_rgb(colormap, hue, sat2, amp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot: HSI representations\n",
    "\n",
    "plt.figure(figsize=(12,12))\n",
    "\n",
    "plt.subplot(2,1,1)\n",
    "plt.imshow(np.transpose(rgb_comp1, axes=(1,0,2)), aspect = 'auto')\n",
    "\n",
    "plt.subplot(2,1,2)\n",
    "plt.imshow(np.transpose(rgb_comp2, axes=(1,0,2)), aspect = 'auto')\n",
    "\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
